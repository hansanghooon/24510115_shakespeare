# 24510115_shakespeare

파일 설명
dataset.py
이 파일에는 데이터 로딩 및 전처리를 위한 Shakespeare 클래스 가 들어있습니다.
해당 클래스는 파일 이름을 인자로 받고, 해당 이름을 가진 txt 파일  불러와 텍스트 파일에서 불러온 문자를 인덱스로 변환 후 길이 30의 시퀀스로 분할합니다.

model.py
이 파일에는 두 개의 클래스가 정의되어있음 :

CharRNN: vanilla RNN 을 기반으로 하는 모델
CharLSTM: LSTM 을 기반으로 하는 모델 .
두 클래스 모두 순전파 및 은닉 상태 초기화를 위한 메서드를 포함합니다.


main.py
이 파일은 훈련 및 검증 로직을 포함합니다:

train(): 모델을 훈련시키고 평균 훈련 손실을 계산합니다.
validate(): 모델을 검증하고 평균 검증 손실을 계산합니다.
main(): 데이터 로더, 모델, 손실 함수 및 옵티마이저를 설정한 후 훈련 및 검증 과정을 실행합니다.

실제 실험은 ipynb에서 진행을 했고, 히든 레이어 를 몇겹으로 쌓아야 가장 효율적인지 테스트 하기 위해서 일단 히든 레이어별 20epoch씩 실험을 한 후.
가장 성능이 좋았던 레이어를 골라서 다시 50 epoch 실험을 진행했습니다.

레이어 개수의 경우 주피터 노트북에서 테스트하고 main.py 를 만듬, 각 layer 별 accuracy와 loss 는 주피터 노트북 내에 plot으로 있습니다. 
![image](https://github.com/hansanghooon/24510115_shakespeare/assets/132417290/b2ffa9ae-e6e0-4ec2-a6ac-db260ade5baf)

![image](https://github.com/hansanghooon/24510115_shakespeare/assets/132417290/e39ba979-6bb6-407d-a75c-1f5c11e2a0c2)


genrate.py
high temperatures (T>1):

높 값은 확률 분포를 부드럽게 하여 더 균일하게 만듭니다. 이는 모델이 덜 확률적인 문자도 샘플링할 가능성이 높아져, 더 다양한 텍스트를 생성하지만덜 일관된 결과를 초래할 가능성이 존재 합니다.


low temperatures (0<𝑇<1):
모델의 예측값에 훨씬더 의존된 결과를 가집니다(새로운 결과가 나오는것이 아니라 확률이 높은 기존의 결과를 선택할 가능성이 높아짐) 이는 예측가능하고 일관된 텍스트를 형성하게 됩니다.



T=1.0인 경우, 생성된 텍스트는 일관성과 다양성의 균형을 유지하여 일반적으로 그럴듯한 결과를 만듭니다.
